# -*- coding: utf-8 -*-
"""MachinaLearning_IRIS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19MdlUW2CqX2eIj8QLAsERXydH5Ab5SEx

# Aprendizado de Máquina na prática e na intuição

Suponha que você foi passear em um campo de flores. Você sabe que lá estão plantadas 3 espécies de flores do gênero Iris. 

Andando pelo campo, você escolhe uma planta aleatoriamente e se pergunta qual a melhor abordagem para classificar essa planta na espécie correta. 

Felizmente, você trouxe um catálogo com você. Esse catálago possui exemplares de pétalas de diferentes espécimes das 3 espécies.

<!-- ![alt text]() -->
![](https://miro.medium.com/max/1275/1*7bnLKsChXq94QjtAiRn40w.png)

# O catálogo

As bibliotecas* *seaborn* e *matplotlib* são utilizadas para gerar gráficos. Nesse exercício, a *seaborn* também provê um catálogo com medidas de vários exemplares de 3 espécies de iris.

\* Bibliotecas são códigos que fornecem funcionalidades específicas.
"""

# Carrega a biblioteca seaborn, e diz que ela será chamada pelo nome sns
import seaborn as sns
# Carrega a biblioteca matplotlib.pyplot, e diz que ela será chamada pelo nome plt
import matplotlib.pyplot as plt

# Carrega o dataset Iris
iris = sns.load_dataset('iris')
# Mostra as 5 primeiras entradas do dataset
iris.head()

# Manipulação dos dados para facilitar algumas operações
iris = iris.assign(species=iris.species.astype('category'))

"""# Análise do catálogo

Você decide usar duas medidas da pétala: comprimento e largura. Cada pétala (e consequentemente planta) é representada por essas duas medidas, formando um par de coordenadas.

**Como é a distribuição do comprimento das pétalas em cada espécie? E a distribuição da largura?**
"""

fig, axes = plt.subplots(1, 2, figsize=(12,5))

# agrupa os dados por espécie
# para cada espécie, plotta a distribuição das medidas da pétala
for name, data in iris.groupby('species'):
    sns.distplot(data['petal_length'], kde=False, label=name, ax=axes[0])
    sns.distplot(data['petal_width'], kde=False, label=name, ax=axes[1])

fig.suptitle('Distribuição do comprimento e da largura da pétala (por espécie)')
_ = plt.legend()

"""Considerando que cada planta é representada pela coordenada `(comprimento, largura)`, **como é a distribuição de plantas por espécie?**"""

ax = sns.scatterplot(x='petal_length', y='petal_width', data=iris, hue='species')
ax.axis('scaled')
_ = ax.set_title('Comprimento vs largura da pétala (por espécie)')

"""Olhando seu catálogo, você percebe que:
- Os exemplares da mesma espécie tem pétalas com tamanhos parecidas;
- Os exemplares de espécies diferentes tem pétalas com tamanhos bem diferentes.

# A abordagem


Você então define a seguinte abordagem:
- Encontre a pétala do catálogo que mais se parece com a pétala que você retirou do campo;
- Diga que as duas pétalas devem ter vindo da mesma espécie.

Você decide usar duas medidas da pétala: comprimento e largura. Cada pétala (e consequentemente planta) é representada por essas duas medidas, formando um par de coordenadas. Para definir o quão distintas duas pétalas são, você utiliza a distância euclidiana.
"""

# numpy é uma biblioteca de manipulação numérica
import numpy as np

#@title Função auxiliar para fazer o scatter plot com pontos de teste
def plot_scatter(catalog, test=None, preds=None):
    ax = sns.scatterplot(x='petal_length', y='petal_width', data=catalog, hue='species')
    ax.axis('scaled')
    ax.set_title('Comprimento vs largura da pétala (por espécie)')
    if test is not None:
        ax.scatter(x=test[:, 0], y=test[:, 1], color='r')
        if preds is not None:
            # Mapeamento do código da espécie para o nome dela: {0: 'setosa', 1: 'versicolor', 2: 'virginica'}
            species_mapping = dict(enumerate(catalog.species.cat.categories))
            for t, p in zip(test, preds):
                _ = ax.annotate(species_mapping[p], t)
    plt.show()

# Seleciona as duas medidas de interesse
X = iris[['petal_length', 'petal_width']]
# Transforma o nome das espécies em números {'setosa': 0, 'versicolor': 1, 'virginica': 2}
y = iris.species.cat.codes

# Exemplo:
# Imprime o par (petal_length, petal_width) e o código da classe
for i in range(5):
    print(X.values[i], y[i])

"""### Exemplo mais próximo"""

#@title Plot classificação de uma instância: { run: "auto" }
length = 6.5 #@param {type:"slider", min:0, max:7.5, step:0.5}
width = 0.5 #@param {type:"slider", min:0, max:3, step:0.1}
 
# define o tamanho da pétala que escolhemos
test = np.array([length, width])
 
smallest_dist = 10**5 # "INF"
nearest_neigh = -1
 
def euclidean_dist(a, b):
    dx = a[0] - b[0]
    dy = a[1] - b[1]
    return np.sqrt(dx**2 + dy**2)
 
# para cada pétala do catálogo
for idx, catalog_example in enumerate(X.values):
    # calcula a distância entre a nossa pétala e a do catálogo
    dist = euclidean_dist(test, catalog_example)
    # se distância é menor, atualiza
    if dist < smallest_dist:
        smallest_dist = dist
        nearest_neigh = idx
 
preds = y[nearest_neigh]
plot_scatter(iris, test.reshape((1, 2)), preds.reshape((-1)))

"""### K-Nearest Neighbors"""

# Scikit-learn é uma biblioteca com vários algoritmos de Aprendizado de Máquina e outras ferramentas
from sklearn.neighbors import KNeighborsClassifier 
# Numpy é uma biblioteca para manipulação numérica
import numpy as np

#@title Plot classificação de uma instância: { run: "auto" }
k = 7 #@param {type:"slider", min:1, max:9, step:1}
length = 5 #@param {type:"slider", min:0, max:7.5, step:0.5}
width = 0.3 #@param {type:"slider", min:0, max:3, step:0.1}
 
test = np.array([[length, width]])
 
neigh = KNeighborsClassifier(n_neighbors=k)
neigh.fit(X, y)
preds = neigh.predict(test)
 
plot_scatter(iris, test, preds)

#@title Plot classificação de instâncias aleatórias: { run: "auto" }
k = 1 #@param {type:"slider", min:1, max:50, step:1}
num = 14 #@param {type:"slider", min:1, max:15, step:1}

neigh = KNeighborsClassifier(n_neighbors=k)
neigh.fit(X, y)

test = np.random.uniform(low=(.5, 0), high=(7.5, 2.5), size=(num, 2))
preds = neigh.predict(test)
plot_scatter(iris, test, preds)

#@title Função para plottar a decision boundary
from matplotlib.colors import ListedColormap

def plot_decision_boundary(k, df, X, y, padding=.5):
    # https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html
    h = .02  # step size in the mesh

    # Create color maps
    cmap_light = ListedColormap(['#AAAAFF', '#FFAAAA', '#AAFFAA'])

    # Plot the decision boundary. For that, we will assign a color to each
    # point in the mesh [x_min, x_max]x[y_min, y_max].
    x_min, x_max = X[:, 0].min() - padding, X[:, 0].max() + padding
    y_min, y_max = X[:, 1].min() - padding, X[:, 1].max() + padding
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                            np.arange(y_min, y_max, h))
    
    clf = KNeighborsClassifier(n_neighbors=k)
    clf.fit(X, y) 
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)

    # Plot also the training points
    fig, ax = plt.subplots(1,1)
    ax.axis('scaled')
    ax.pcolormesh(xx, yy, Z, cmap=cmap_light)
    sns.scatterplot(x='petal_length', y='petal_width', data=df, hue='species', ax=ax)
    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    plt.title("3-Class classification (k = %i)" % k)

    plt.show()

#@title Plot decision boundary: { run: "auto" }
k = 50 #@param {type:"slider", min:1, max:50, step:1}
plot_decision_boundary(k, iris, X.values, y)

plot_decision_boundary(1, iris, X.values, y)

plot_decision_boundary(3, iris, X.values, y)

plot_decision_boundary(5, iris, X.values, y)

"""# Reflexões
- E se k = n (o tamanho da amostra)?
- E se a pétala colhida for de uma espécie que não tem no catálogo?
- E se a pétala colhida for de um espécime anômalo, isto é, de uma planta que foge muito do padrão da espécie dela?
- Ouve aprendizado? Por que sim/não?

# Árvore de decisão
"""

from sklearn import tree
import graphviz

# Seleciona as duas medidas de interesse
X = iris[['petal_length', 'petal_width']]
# Transforma o nome das espécies em números {'setosa': 0, 'versicolor': 1, 'virginica': 2}
y = iris.species.cat.codes

#@title Função auxiliar para plottar a decision boundary
# Parameters
n_classes = 3
plot_colors = "ryb"
plot_step = 0.02

def tree_plot_decision_boundary(clf, X, y, iris):
    x_min, x_max = X.values[:, 0].min() - 1, X.values[:, 0].max() + 1
    y_min, y_max = X.values[:, 1].min() - 1, X.values[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),
                            np.arange(y_min, y_max, plot_step))
    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)

    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)

    plt.xlabel(X.columns[0])
    plt.ylabel(X.columns[1])

    species_mapping = dict(enumerate(iris.species.cat.categories))
    # Plot the training points
    for i, color in zip(range(n_classes), plot_colors):
        idx = np.where(y == i)
        plt.scatter(X.values[idx, 0], X.values[idx, 1], c=color, label=species_mapping[i],
                    cmap=plt.cm.RdYlBu, edgecolor='black', s=15)

    plt.suptitle("Decision surface of a decision tree using paired features")
    plt.legend(loc='lower right', borderpad=0, handletextpad=0)
    # plt.axis("tight")
    plt.axis('scaled')

#@title Plot árvore e decision boundary: { run: "auto" }

max_depth = 4 #@param {type:"slider", min:1, max:10, step:1}
clf = tree.DecisionTreeClassifier(max_depth=max_depth)
clf = clf.fit(X, y)

tree_plot_decision_boundary(clf, X, y, iris)

dot_data = tree.export_graphviz(clf, out_file=None, 
                     feature_names=X.columns,  
                     class_names=iris['species'].unique(),
                     filled=True, rounded=True,  impurity=False,
                     special_characters=True)  
graph = graphviz.Source(dot_data)  
graph

#@title Plot classificação de uma instância: { run: "auto" }
length = 1.5 #@param {type:"slider", min:0, max:7.5, step:0.5}
width = 1.5 #@param {type:"slider", min:0, max:3, step:0.1}

test = np.array([[length, width]])
preds = clf.predict(test)
plot_scatter(iris, test, preds)

